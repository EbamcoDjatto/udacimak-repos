{
  "data": {
    "lesson": {
      "id": 518718,
      "key": "9030e3b5-5e66-4e2b-97a3-351758b5f1f6",
      "title": "Linear Algebra in Neural Networks",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Take a peek into the world of Neural Networks and see how it related directly to Linear Algebra!",
      "lesson_type": "Classroom",
      "display_workspace_project_only": null,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/9030e3b5-5e66-4e2b-97a3-351758b5f1f6/518718/1544456072053/Linear+Algebra+in+Neural+Networks+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/9030e3b5-5e66-4e2b-97a3-351758b5f1f6/518718/1544456069402/Linear+Algebra+in+Neural+Networks+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 571947,
          "key": "d4e4f5c9-0c55-4e6c-9f6d-1fec57cfb218",
          "title": "Instructor",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "d4e4f5c9-0c55-4e6c-9f6d-1fec57cfb218",
            "completed_at": "2020-04-07T01:03:08.806Z",
            "last_viewed_at": "2020-04-07T01:03:08.431Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 587477,
              "key": "f4f6ec53-d9ef-419f-9bf6-4bec310d634e",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/April/5ac2cd93_cp1a9390/cp1a9390.jpg",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/f4f6ec53-d9ef-419f-9bf6-4bec310d634e",
              "caption": "_Ortal Arel_",
              "alt": "",
              "width": 300,
              "height": 300,
              "instructor_notes": null
            },
            {
              "id": 587479,
              "key": "13e86c72-e63e-4dd7-97e0-88057f99e2bd",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Hello Again!\n\n\nOrtal will now show you how beautifully **Linear Algebra** is used  to define an artificial neural network. ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 527996,
          "key": "89f57299-949b-44f8-afc7-cf1ddfd58b6c",
          "title": "Brief Introduction ",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "89f57299-949b-44f8-afc7-cf1ddfd58b6c",
            "completed_at": "2020-04-07T01:03:12.890Z",
            "last_viewed_at": "2020-04-07T01:05:21.592Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 528005,
              "key": "d2d429fa-2311-4718-8a4b-1324a99adfb5",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Brief Introduction ",
              "instructor_notes": ""
            },
            {
              "id": 527997,
              "key": "863758e6-6418-484f-bba4-3623a37a05e9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "You may ask yourselves why are we taking the time to go over Linear Algebra with you. We emphasized in the introduction that Linear Algebra is a beautiful field in mathematics that helps apply and understand many disciplines, such as Statistics, Computer Science, Economics, but also, and in particular what we would like to focus on here, are the  **Neural Networks**!",
              "instructor_notes": ""
            },
            {
              "id": 527998,
              "key": "8f14d67f-f301-4cac-94e4-74c1ee8239b8",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The next lesson (or module) in this nanodegree will give you an elaborate overview of neural networks. But before you dive into the lukewarm water, lets take a brief glimpse.\n\nHere, we will give you an oversimplified idea of what a neural network is for the purpose of understanding how beautifully Linear Algebra is an ingrained component in it's application. In a nut shell, please focus on the math and how it's applied.  It's OK if a few topics related directly to neural networks are still left unclear, as the entire neural network lesson is coming up soon.",
              "instructor_notes": ""
            },
            {
              "id": 528002,
              "key": "b1edde75-7638-4896-8b5c-b2869fad303a",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a720ed9_screen-shot-2018-01-31-at-10.45.20-am/screen-shot-2018-01-31-at-10.45.20-am.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/b1edde75-7638-4896-8b5c-b2869fad303a",
              "caption": "",
              "alt": "",
              "width": 400,
              "height": 300,
              "instructor_notes": null
            }
          ]
        },
        {
          "id": 528003,
          "key": "7dd7917d-de4c-43d5-b520-e024aaf8d6cb",
          "title": "What is a Neural Network?",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "7dd7917d-de4c-43d5-b520-e024aaf8d6cb",
            "completed_at": "2020-04-07T01:05:42.062Z",
            "last_viewed_at": "2020-04-07T01:05:41.712Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 528004,
              "key": "3b5bf45a-2f92-429c-8b6d-176d2a969db0",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# What is a Neural Network?",
              "instructor_notes": ""
            },
            {
              "id": 528008,
              "key": "b3b3264e-f95c-4bb0-ac1a-b6590183de6f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Neural networks is an important area of research in neuroscience. When we, as computer scientists, engineers, or other professionals outside the scope of pure neuroscience refer to neural networks, we actually mean **artificial neural networks**.",
              "instructor_notes": ""
            },
            {
              "id": 528031,
              "key": "a95952ff-85e5-4f24-a0de-64a1f0725685",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The following is a fun short movie that will give you a nice visualization of these **biological** neural networks.\n",
              "instructor_notes": ""
            },
            {
              "id": 549566,
              "key": "621e13ee-3c15-46b6-8f86-7aa716b612ab",
              "title": "Dolly Inside Head  1 ",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "tyam5ZncjNw",
                "china_cdn_id": "tyam5ZncjNw.mp4"
              }
            },
            {
              "id": 528044,
              "key": "77f2dd4b-927e-4c9e-981b-18003b84e73d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The design of the  **Artificial Neural Network** was inspired by the biological one.  The neurons used in the artificial network below are essentially mathematical functions. \n\nEach network has:\n-  Input neurons- which we refer to as the _input layer_ of neurons\n- Output neurons- which we refer to as the _output layer_ of neurons\n\nand \n- Internal neurons- which we refer to as the _hidden layer_ of neurons. Each neural network can have many hidden layers\n\n\nThe following picture is of a simple neural network with a single hidden layer. ",
              "instructor_notes": ""
            },
            {
              "id": 528046,
              "key": "4372785a-e45c-445b-9df9-20e0b6dc149e",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a7241d0_screen-shot-2018-01-31-at-2.22.49-pm/screen-shot-2018-01-31-at-2.22.49-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/4372785a-e45c-445b-9df9-20e0b6dc149e",
              "caption": "_Simplified Artificial Neural Network_",
              "alt": "",
              "width": 400,
              "height": 300,
              "instructor_notes": null
            },
            {
              "id": 528047,
              "key": "79af17e9-2132-442a-80b5-3602dc5b2015",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "This version of a simplified artificial neural network is comprised out of:\n\n-  An input vector <span class=\"mathquill\">\\vec{x}=\\begin{bmatrix} x_1\n& x_2\n& x_3\n& ...\n&x_n\n\\end{bmatrix}</span>\n\n\n- A hidden layer vector <span class=\"mathquill\">\\vec{h}=\\begin{bmatrix} h_1\n& h_2\n& h_3\n& ...\n&h_m\n\\end{bmatrix}</span>\n\nand \n-  An output vector <span class=\"mathquill\">\\vec{y}=\\begin{bmatrix} y_1\n& y_2\n& y_3\n& ...\n&y_k\n\\end{bmatrix}</span>",
              "instructor_notes": ""
            },
            {
              "id": 528050,
              "key": "32f44f83-2202-4e45-8af8-2fc643566f42",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Each element in the vectors is a mathematical argument which we will elaborate on very soon.\n\nNotice that there is no connection between the number of inputs,  number of hidden neurons in the hidden layer or number of outputs.\n\n(The notation we used here is of a row vector, these vectors can be expressed as column vectors as well)\n ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 528051,
          "key": "eed82d5f-99d2-4793-a6f2-cba704e9b2e8",
          "title": "How Are The Neurons Connected?",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "eed82d5f-99d2-4793-a6f2-cba704e9b2e8",
            "completed_at": "2020-04-07T01:07:40.640Z",
            "last_viewed_at": "2020-04-07T01:07:39.575Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 528052,
              "key": "7bb0a021-2da5-4f11-9113-6d6cf491e37f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# How Are The Neurons Connected?",
              "instructor_notes": ""
            },
            {
              "id": 528053,
              "key": "b6a8bd1d-aeaf-4b2e-8377-107d832198a9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Let's go back to the picture we just saw:",
              "instructor_notes": ""
            },
            {
              "id": 528054,
              "key": "f4ad4813-b92c-49a9-9631-308777de9d25",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a724492_screen-shot-2018-01-31-at-2.22.49-pm/screen-shot-2018-01-31-at-2.22.49-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/f4ad4813-b92c-49a9-9631-308777de9d25",
              "caption": "_Simplified Artificial Neural Network_",
              "alt": "",
              "width": 400,
              "height": 300,
              "instructor_notes": null
            },
            {
              "id": 528055,
              "key": "24edc87a-60b4-47d1-b8d8-0582484fb905",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Notice the \"lines\" connecting the different neurons? \n\n- In practice, these lines symbolize a coefficient (a scalar) that is mathematically connecting one neuron to the next.  These coefficients are called **weights**.\n\n-  The \"lines\" connect each neuron in a specific layer to **all** of the neurons on the following. For example, in our example, you can see how each neuron in the hidden layer is connected to a neuron in the output one. \n",
              "instructor_notes": ""
            },
            {
              "id": 528057,
              "key": "154f4754-ddd7-41fb-8e0a-9824a3727b2e",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Since there are so many **weights** connecting one layer to the next, we mathematically organize those coefficients in a matrix, denoted as the **weight matrix**. ",
              "instructor_notes": ""
            },
            {
              "id": 528059,
              "key": "e17f2435-b7e6-4db2-9b10-96c0d02f53df",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/January/5a7248c3_screen-shot-2018-01-31-at-2.52.19-pm/screen-shot-2018-01-31-at-2.52.19-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/e17f2435-b7e6-4db2-9b10-96c0d02f53df",
              "caption": "_Simplified Artificial Neural Network With A Weight Matrix_",
              "alt": "",
              "width": 400,
              "height": 300,
              "instructor_notes": null
            },
            {
              "id": 528060,
              "key": "e6766693-f3f0-4ce5-a7d9-0cc65ac02247",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Spoiler: \n\nLater you will learn that when we train an artificial neural network, we are actually looking for the best set of weights that will give us a desired outcome. We will not focus on that here, in the context of Linear Algebra.",
              "instructor_notes": ""
            },
            {
              "id": 528061,
              "key": "87e8e95d-24ad-4937-8e8c-d5d9e3b06593",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "OK! \nSo what does all of this have to do with Linear Algebra?! Lets see!",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 528062,
          "key": "ebc4a2f1-066c-4805-ae3a-6e1e2e7738bf",
          "title": "Putting The Pieces Together",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "ebc4a2f1-066c-4805-ae3a-6e1e2e7738bf",
            "completed_at": "2020-04-07T01:08:04.192Z",
            "last_viewed_at": "2020-04-07T01:08:03.841Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 528063,
              "key": "fc5691bc-242f-4f01-abad-e90fb2b0ee85",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "\n#  Putting The Pieces Together",
              "instructor_notes": ""
            },
            {
              "id": 528066,
              "key": "9cfd27a2-9455-4bb6-b25f-7f19176087ae",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "In the following videos we use subscripts as well as superscript as a numeric notation for the weight matrix.\n\nFor example:\n-  <span class=\"mathquill\"> W_k</span> is weight matrix <span class=\"mathquill\"> k</span> \n- <span class=\"mathquill\">\\ W_{ij}^k</span>  is the <span class=\"mathquill\"> ij</span>  element of weight matrix  <span class=\"mathquill\"> k</span> ",
              "instructor_notes": ""
            },
            {
              "id": 549569,
              "key": "b7f7e0d8-2bdf-48bb-884a-479ad946ae11",
              "title": "LinearAlgebra 05 RNN FFNN Reminder PAIND 82mp4 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "SSgQRH-V-1k",
                "china_cdn_id": "SSgQRH-V-1k.mp4"
              }
            },
            {
              "id": 528069,
              "key": "f60cd541-9c32-43d1-b21a-e2f91ff26de9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Notice that the video introduces a concept we have't mentioned yet, the **activation function**. No worries, you will learn all about it in the next lesson (Introduction to Neural Networks). ",
              "instructor_notes": ""
            },
            {
              "id": 528074,
              "key": "4a3aca1a-1ce4-4604-ba4f-9424c93df38d",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "When working with neural networks we have 2 primary phases:\n\n- Training\n\nand\n\n- Evaluation.\n\nDuring the training phase, we take the data set (also called the training set), which includes many pairs of inputs and their corresponding targets (outputs). Our goal is to find a set of weights that would best map the inputs to the desired outputs. \n\nIn the evaluation phase, we use the network that was created in the training phase, apply our new inputs and expect to obtain the desired outputs.\n\nThe training phase will include two steps:\n\n- Feedforward\n\nand\n\n- Backpropagation\n\nWe will repeat these steps as many times as we need until we decide that our system has reached the best set of weights, giving us the best possible outputs.\n\n",
              "instructor_notes": ""
            },
            {
              "id": 528075,
              "key": "edfdc846-f99e-45c2-a807-c3bd17817898",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "To show you how relevant Linear Algebra is here, we will focus on the **feedforward** process.  And again, focus on the mathematical calculations. All of these new definitions (training, evaluation, feedforward,  backpropagation, etc will be emphasized very soon!)",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 528070,
          "key": "0137eb63-d76c-49ef-a205-f07892a6db42",
          "title": "The Feedforward Process- Finding h",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "0137eb63-d76c-49ef-a205-f07892a6db42",
            "completed_at": "2020-04-07T01:13:23.890Z",
            "last_viewed_at": "2020-04-07T01:13:23.004Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 528076,
              "key": "0e7f6594-0828-4352-81f9-757b283c5160",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# The Feedforward Process- Finding <span class=\"mathquill\">\\vec{h} </span>\n",
              "instructor_notes": ""
            },
            {
              "id": 528111,
              "key": "58f24322-78cb-4707-aad3-0d1d6ef88508",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "In this section we will look closely at the math behind the **feedforward** process. With the use of basic Linear Algebra tools, these calculations are pretty simple! ",
              "instructor_notes": ""
            },
            {
              "id": 528112,
              "key": "cdf835a7-0074-4a84-a0bb-07c04b8de0f2",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Assuming that we have a single hidden layer, we will need two steps in our calculations. The first will be calculating the value of the hidden states and the latter will be calculating the value of the outputs.\n",
              "instructor_notes": ""
            },
            {
              "id": 528113,
              "key": "98cae810-5804-4e02-8699-b4f6d5a6a428",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/February/5a725c10_screen-shot-2018-01-31-at-4.14.50-pm/screen-shot-2018-01-31-at-4.14.50-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/98cae810-5804-4e02-8699-b4f6d5a6a428",
              "caption": "",
              "alt": "",
              "width": 394,
              "height": 248,
              "instructor_notes": null
            },
            {
              "id": 528114,
              "key": "f056081f-236e-421d-816a-56bee1c27cc9",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Notice that both the hidden layer and the output layer are displayed as vectors, as they are both represented by more than a single neuron. ",
              "instructor_notes": ""
            },
            {
              "id": 528115,
              "key": "9009d8d3-fd1a-4129-a396-7bdbc457ac7c",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": " Our first video will help you understand the first step- **Calculating the value of the hidden states**.",
              "instructor_notes": ""
            },
            {
              "id": 549572,
              "key": "f423b4c3-104f-4291-8b2c-4612fd8fae18",
              "title": "Linear Algebra 06 FeedForward A V7 PAIND83 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "kQ6rNndcA1I",
                "china_cdn_id": "kQ6rNndcA1I.mp4"
              }
            },
            {
              "id": 528119,
              "key": "5c282b1e-ac98-4bce-aebf-3e33bb5c2acb",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "As you saw in the video above, vector <span class=\"mathquill\">\\vec{h'} </span> of the hidden layer will be calculated by multiplying the input vector with the weight matrix  <span class=\"mathquill\">W^{1}</span> the following way:\n\n<span class=\"mathquill\">\\vec{h'} = (\\bar{x}  W^1 )</span>\n\nUsing vector by matrix multiplication, we can look at this computation the following way:",
              "instructor_notes": ""
            },
            {
              "id": 528120,
              "key": "3067f735-8430-4e24-a383-3effeb6be08f",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/February/5a725e7c_screen-shot-2018-01-31-at-4.25.16-pm/screen-shot-2018-01-31-at-4.25.16-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/3067f735-8430-4e24-a383-3effeb6be08f",
              "caption": "_Equation 17_",
              "alt": "",
              "width": 400,
              "height": 100,
              "instructor_notes": null
            },
            {
              "id": 528121,
              "key": "3aa58dc8-00d0-4a3f-96d0-7c927040011a",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "\nAfter finding <span class=\"mathquill\">\\vec{h'} </span>  we need an activation function. \n\nThe symbol we use for the activation function is the Greek letter phi: <span class=\"mathquill\">\n \\Phi</span>. \n\nThis activation function finalizes the computation of the hidden layer's values. \n\nWe can use the following two equations to express the final hidden vector <span class=\"mathquill\">\\vec{h'} </span>:\n\n<span class=\"mathquill\">\\vec{h} = \\Phi(\\vec{x}  W^1 )</span> \n\nor\n \n <span class=\"mathquill\"> \\vec{h} = \\Phi(\\vec{h'})</span>\n\n\nSince <span class=\"mathquill\">W_{ij}</span>\nrepresents the weight component in the weight matrix, connecting neuron **i** from the input to neuron **j** in the hidden layer, we can also write these calculations using a **linear combination**:\n(notice that in this example we have *n* inputs and only 3 hidden neurons)\n",
              "instructor_notes": ""
            },
            {
              "id": 528122,
              "key": "f1266e88-f85b-4655-b3bf-49914a4661df",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/February/5a725f86_screen-shot-2018-01-31-at-4.29.38-pm/screen-shot-2018-01-31-at-4.29.38-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/f1266e88-f85b-4655-b3bf-49914a4661df",
              "caption": "_Equation 18_",
              "alt": "",
              "width": 300,
              "height": 200,
              "instructor_notes": null
            },
            {
              "id": 528123,
              "key": "28eca468-559f-4619-ab2c-38419824978c",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "More information on the activation functions and how to use them will be found in the next lesson (Introduction to Neural Networks).",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 550286,
          "key": "8d26152b-c8d9-41a1-9cd3-95a3ac6aec8f",
          "title": "The Feedforward Process- Finding y",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "8d26152b-c8d9-41a1-9cd3-95a3ac6aec8f",
            "completed_at": "2020-04-07T01:19:45.293Z",
            "last_viewed_at": "2020-04-07T01:19:44.369Z",
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 550287,
              "key": "68b7aeb2-241a-4937-bf75-091d9ab8b645",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# The Feedforward Process- Finding <span class=\"mathquill\">\\vec{y} </span>\n",
              "instructor_notes": ""
            },
            {
              "id": 550290,
              "key": "19041b5e-7a6a-440e-a452-0a0a1a3b842b",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "We finished our first step, finding <span class=\"mathquill\">\\vec{h} </span>, and now need to find the output  <span class=\"mathquill\">\\vec{y} </span>\n\n\n",
              "instructor_notes": ""
            },
            {
              "id": 550291,
              "key": "9835a252-dac9-4d46-83e8-bd6729d8c1f6",
              "title": "LinearAlgebra 07 FeedForward PAIND85 V3",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "pvF6jpS_-cU",
                "china_cdn_id": "pvF6jpS_-cU.mp4"
              }
            },
            {
              "id": 550293,
              "key": "0ff82674-debe-439e-9d1c-b48d41cdb34e",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "As you've seen in the video above, the process of calculating the output vector is mathematically similar to that of calculating the vector of the hidden layer. We use, again, a vector by matrix multiplication. The vector is the newly calculated hidden layer and the matrix is the one connecting the hidden layer to the output.\n",
              "instructor_notes": ""
            },
            {
              "id": 550295,
              "key": "4160d058-500e-4d71-b93c-ee6c7e301c69",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/February/5a8743de_screen-shot-2018-02-16-at-12.49.05-pm/screen-shot-2018-02-16-at-12.49.05-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/4160d058-500e-4d71-b93c-ee6c7e301c69",
              "caption": "",
              "alt": "",
              "width": 200,
              "height": 200,
              "instructor_notes": null
            },
            {
              "id": 550296,
              "key": "346ceaa6-7de3-4d64-8856-dd8a0c146783",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Essentially, each new layer in an neural network is calculated by a vector by matrix multiplication, where the vector represents the inputs to the new layer and the matrix is the one connecting these new inputs to the next layer.\n\nIn our example, the input vector is <span class=\"mathquill\">\\vec{h}</span> and the matrix is  <span class=\"mathquill\">W^2</span>, therefore  <span class=\"mathquill\">\\vec{y}=\\vec{h}W^2</span>. ",
              "instructor_notes": ""
            },
            {
              "id": 550297,
              "key": "6f43f6f6-b26a-499b-83ff-b1bd085e34cd",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/February/5a874420_screen-shot-2018-02-16-at-12.50.25-pm/screen-shot-2018-02-16-at-12.50.25-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/6f43f6f6-b26a-499b-83ff-b1bd085e34cd",
              "caption": "_Equation 19_",
              "alt": "",
              "width": 300,
              "height": 100,
              "instructor_notes": null
            },
            {
              "id": 550301,
              "key": "0f80ea29-9c08-4342-8884-3991637ebc2e",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "The video above also generalizes the model we have been talking about. \n\n\nMore on this issue in out next module  **Neural Networks**!.",
              "instructor_notes": ""
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}